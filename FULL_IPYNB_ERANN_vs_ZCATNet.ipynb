{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08155861",
   "metadata": {},
   "source": [
    "# FULL IPYNB — Baseline (Energy Reports 2024) vs Proposed Z-CATNet (Research-ready)\n",
    "\n",
    "Notebook end-to-end:\n",
    "1) Load dữ liệu (UCI txt hoặc CSV)  \n",
    "2) Resample 15 phút → DLP 96 điểm/ngày  \n",
    "3) Weekday pattern (mean/std) → Z-score (giống paper)  \n",
    "4) Feature 99 = 96 Z + max/mean/min  \n",
    "5) Nếu chưa có nhãn: pseudo-label 33 lớp (multi-label) để chạy demo end-to-end  \n",
    "6) Train Baseline ER-ANN (y chang paper)  \n",
    "7) Train Proposed Z-CATNet (CNN + BiLSTM + Self-Attention + Focal Loss)  \n",
    "8) Evaluate + export CSV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df2e03b",
   "metadata": {},
   "source": [
    "## 0) Cài thư viện (nếu chạy local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff16deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q pandas numpy scikit-learn matplotlib tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5304377",
   "metadata": {},
   "source": [
    "## 1) Load dữ liệu (UCI txt hoặc CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7da579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_TYPE = \"UCI_TXT\"   # \"UCI_TXT\" hoặc \"CSV\"\n",
    "\n",
    "UCI_PATH = r\"D:\\AIL303c\\data\\household_power_consumption.txt\"   # <-- SỬA\n",
    "\n",
    "CSV_PATH = r\"D:\\your_data.csv\"  # <-- SỬA\n",
    "CSV_TS_COL = \"timestamp\"\n",
    "CSV_VAL_COL = \"power\"\n",
    "CSV_AGG = \"mean\"  # \"mean\"(kW) hoặc \"sum\"(kWh)\n",
    "\n",
    "def load_series():\n",
    "    if DATA_TYPE == \"UCI_TXT\":\n",
    "        df = pd.read_csv(UCI_PATH, sep=\";\", na_values=\"?\", low_memory=False)\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"Date\"] + \" \" + df[\"Time\"], dayfirst=True, errors=\"coerce\")\n",
    "        df = df[[\"timestamp\", \"Global_active_power\"]].dropna()\n",
    "        df = df.sort_values(\"timestamp\").set_index(\"timestamp\")\n",
    "        s = df[\"Global_active_power\"].astype(float)\n",
    "        return s, \"kW_mean\"\n",
    "    else:\n",
    "        df = pd.read_csv(CSV_PATH)\n",
    "        df[CSV_TS_COL] = pd.to_datetime(df[CSV_TS_COL])\n",
    "        df = df.sort_values(CSV_TS_COL).set_index(CSV_TS_COL)\n",
    "        s = df[CSV_VAL_COL].astype(float)\n",
    "        return s, (\"kWh_sum\" if CSV_AGG==\"sum\" else \"kW_mean\")\n",
    "\n",
    "raw_series, series_kind = load_series()\n",
    "print(\"Loaded:\", raw_series.shape, \"| kind:\", series_kind)\n",
    "raw_series.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c33efe3",
   "metadata": {},
   "source": [
    "## 2) Resample 15 phút + xử lý missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0683c72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_15m = raw_series.resample(\"15min\").mean() if series_kind == \"kW_mean\" else raw_series.resample(\"15min\").sum()\n",
    "s_15m = s_15m.interpolate(method=\"time\", limit_direction=\"both\")\n",
    "s_15m = s_15m.fillna(s_15m.median())\n",
    "print(\"NaN after cleaning:\", int(s_15m.isna().sum()))\n",
    "s_15m.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973b8d03",
   "metadata": {},
   "source": [
    "## 3) DLP 96 điểm/ngày"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c19011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_daily_matrix(series_15m: pd.Series):\n",
    "    days, idx = [], []\n",
    "    for d, chunk in series_15m.groupby(series_15m.index.date):\n",
    "        if len(chunk) < 96:\n",
    "            continue\n",
    "        arr = chunk.iloc[:96].values.astype(float)\n",
    "        if np.isnan(arr).any():\n",
    "            continue\n",
    "        days.append(arr)\n",
    "        idx.append(pd.Timestamp(d))\n",
    "    X_raw = np.vstack(days) if len(days) else np.empty((0, 96))\n",
    "    dates = pd.DatetimeIndex(idx)\n",
    "    return X_raw, dates\n",
    "\n",
    "X_raw, dates = build_daily_matrix(s_15m)\n",
    "print(\"X_raw:\", X_raw.shape, \"| date range:\", dates.min(), \"->\", dates.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf6e891",
   "metadata": {},
   "source": [
    "## 4) Weekday pattern + Z-score (giống paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5defdf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weekday_patterns(X_raw, dates, min_days=5):\n",
    "    patterns = {}\n",
    "    for w in range(7):\n",
    "        mask = (dates.weekday == w)\n",
    "        Xw = X_raw[mask]\n",
    "        if len(Xw) < min_days:\n",
    "            continue\n",
    "        mu = np.mean(Xw, axis=0)\n",
    "        sd = np.std(Xw, axis=0, ddof=1)\n",
    "        patterns[w] = (mu, sd)\n",
    "    return patterns\n",
    "\n",
    "def z_normalize_by_weekday(X_raw, dates, patterns, eps=1e-6):\n",
    "    Z = np.zeros_like(X_raw, dtype=float)\n",
    "    avail = sorted(patterns.keys())\n",
    "    if not avail:\n",
    "        raise ValueError(\"Không đủ dữ liệu để tạo weekday pattern. Cần nhiều ngày hơn.\")\n",
    "    for i, d in enumerate(dates):\n",
    "        w = int(d.weekday())\n",
    "        if w not in patterns:\n",
    "            w = avail[0]\n",
    "        mu, sd = patterns[w]\n",
    "        sd_safe = np.where((sd < eps) | np.isnan(sd), 1.0, sd)\n",
    "        Zi = (X_raw[i] - mu) / sd_safe\n",
    "        Z[i] = np.nan_to_num(Zi, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    return Z\n",
    "\n",
    "patterns = compute_weekday_patterns(X_raw, dates, min_days=5)\n",
    "Z = z_normalize_by_weekday(X_raw, dates, patterns)\n",
    "print(\"pattern weekdays:\", sorted(patterns.keys()))\n",
    "print(\"Z:\", Z.shape, \"| NaN:\", int(np.isnan(Z).sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768fc824",
   "metadata": {},
   "source": [
    "## 5) Feature 99 + plot 1 ngày"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fcfc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_max = X_raw.max(axis=1)\n",
    "daily_mean = X_raw.mean(axis=1)\n",
    "daily_min = X_raw.min(axis=1)\n",
    "\n",
    "X_99 = np.column_stack([Z, daily_max, daily_mean, daily_min])\n",
    "print(\"X_99:\", X_99.shape)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(Z[0])\n",
    "plt.title(f\"Z-score DLP (date={dates[0].date()})\")\n",
    "plt.xlabel(\"slot (0..95)\"); plt.ylabel(\"Z\"); plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6092f755",
   "metadata": {},
   "source": [
    "## 6) Labels 33 lớp (pseudo-label nếu chưa có label thật)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d24685",
   "metadata": {},
   "outputs": [],
   "source": [
    "HAVE_TRUE_LABELS = False\n",
    "\n",
    "SLOTS = {\n",
    "    \"night\": np.arange(0, 24),\n",
    "    \"early\": np.arange(24, 32),\n",
    "    \"work\":  np.arange(32, 72),\n",
    "    \"eve\":   np.arange(72, 96),\n",
    "}\n",
    "\n",
    "def catalog_33_pseudo(Z, X_raw, z_thr=2.0):\n",
    "    n = Z.shape[0]\n",
    "    Y = np.zeros((n, 33), dtype=int)\n",
    "    out = (np.abs(Z) >= z_thr)\n",
    "    night, early, work, eve = SLOTS[\"night\"], SLOTS[\"early\"], SLOTS[\"work\"], SLOTS[\"eve\"]\n",
    "    nonwork = np.r_[night, early, eve]\n",
    "\n",
    "    for i in range(n):\n",
    "        out_any = out[i]\n",
    "        meanZ, maxZ, minZ = np.mean(Z[i]), np.max(Z[i]), np.min(Z[i])\n",
    "        f_all = np.mean(out_any)\n",
    "        f_work = np.mean(out_any[work])\n",
    "        f_non = np.mean(out_any[nonwork])\n",
    "\n",
    "        if not out_any.any(): Y[i,0] = 1\n",
    "        x = X_raw[i]\n",
    "        if np.mean(np.isclose(np.diff(x), 0.0, atol=1e-4)) > 0.30: Y[i,1] = 1\n",
    "        if f_work > 0.15: Y[i,2] = 1\n",
    "        if out_any[work].any() and (not out_any[nonwork].any()): Y[i,3] = 1\n",
    "        if out_any[work].any() and (not out_any[early].any()): Y[i,4] = 1\n",
    "        if np.mean(out_any[night]) > 0.10 and np.mean(Z[i, night] > z_thr) > 0.05: Y[i,5] = 1\n",
    "        if np.mean(out_any[early]) > 0.10: Y[i,6] = 1\n",
    "        if (not out_any[night].any()) and out_any[work].any(): Y[i,7] = 1\n",
    "        if out_any[night].any(): Y[i,8] = 1\n",
    "        if np.mean(out_any[early]) > 0.25: Y[i,9] = 1\n",
    "        if np.mean(out_any[night]) > 0.25: Y[i,10] = 1\n",
    "        if (f_non > f_work + 0.05) and (abs(meanZ) < 0.2): Y[i,11] = 1; Y[i,12] = 1\n",
    "        if (0 < f_all < 0.05) and (abs(meanZ) < 0.2): Y[i,13] = 1\n",
    "        if (f_work > f_non + 0.05) and (abs(meanZ) < 0.2): Y[i,14] = 1\n",
    "        if meanZ > 0.5: Y[i,15] = 1\n",
    "        if meanZ < -0.5: Y[i,16] = 1\n",
    "        if (np.max(Z[i, work]) >= z_thr) and (np.max(Z[i, eve]) >= z_thr): Y[i,17] = 1\n",
    "        if (np.mean(Z[i, work]) < -0.3) and (np.max(Z[i, work]) < 0.5): Y[i,18] = 1\n",
    "        if (minZ > -0.2) and (np.mean(Z[i] > 0.5) > 0.10): Y[i,19] = 1\n",
    "        if minZ <= -z_thr: Y[i,20] = 1\n",
    "        if meanZ > 0.7: Y[i,21] = 1\n",
    "        if meanZ < -0.7: Y[i,22] = 1\n",
    "        if maxZ >= z_thr: Y[i,23] = 1\n",
    "        if (np.max(Z[i]) < 0.3) and (np.mean(Z[i, work]) < -0.4): Y[i,24] = 1\n",
    "        if minZ >= z_thr: Y[i,25] = 1\n",
    "        if minZ <= -z_thr: Y[i,26] = 1\n",
    "        if np.mean(Z[i, work]) > 0.6: Y[i,27] = 1\n",
    "        if (np.min(Z[i]) > -0.2) and (np.mean(Z[i] > 0.4) > 0.20): Y[i,28] = 1\n",
    "        if np.max(Z[i, work]) > (z_thr + 0.5): Y[i,29] = 1\n",
    "        if np.mean(Z[i, work]) < -0.6: Y[i,30] = 1\n",
    "        if Y[i,25] == 1: Y[i,31] = 1\n",
    "        if Y[i,26] == 1: Y[i,32] = 1\n",
    "    return Y\n",
    "\n",
    "if HAVE_TRUE_LABELS:\n",
    "    raise NotImplementedError(\"Load nhãn thật của bạn vào Y_33 ở đây.\")\n",
    "else:\n",
    "    Y_33 = catalog_33_pseudo(Z, X_raw, z_thr=2.0)\n",
    "\n",
    "print(\"Y_33:\", Y_33.shape, \"| avg labels/day:\", float(Y_33.sum(axis=1).mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64b7862",
   "metadata": {},
   "source": [
    "## 7) Split train/test + Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e91b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_99, Y_33, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s  = scaler.transform(X_test)\n",
    "\n",
    "print(\"Train:\", X_train_s.shape, y_train.shape, \"| Test:\", X_test_s.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae1d90f",
   "metadata": {},
   "source": [
    "## 8) Baseline ER-ANN (paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6777dc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_er_ann():\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(99,)),\n",
    "        layers.Dense(100, activation=\"relu\"),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(33, activation=\"sigmoid\")\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[keras.metrics.BinaryAccuracy(name=\"bin_acc\")])\n",
    "    return model\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(patience=5)\n",
    "]\n",
    "\n",
    "er_ann = build_er_ann()\n",
    "hist_er = er_ann.fit(X_train_s, y_train, validation_split=0.2, epochs=50, batch_size=64, callbacks=callbacks, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914d1c9d",
   "metadata": {},
   "source": [
    "## 9) Proposed Z-CATNet (CNN + BiLSTM + Self-Attention + Focal Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af342f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def loss(y_true, y_pred):\n",
    "        eps = 1e-7\n",
    "        y_pred = tf.clip_by_value(y_pred, eps, 1. - eps)\n",
    "        ce = -y_true * tf.math.log(y_pred) - (1 - y_true) * tf.math.log(1 - y_pred)\n",
    "        w = alpha * y_true * tf.pow(1 - y_pred, gamma) + (1 - alpha) * (1 - y_true) * tf.pow(y_pred, gamma)\n",
    "        return tf.reduce_mean(w * ce)\n",
    "    return loss\n",
    "\n",
    "class SelfAttention(layers.Layer):\n",
    "    def __init__(self, d_k=64, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.d_k = d_k\n",
    "        self.q = layers.Dense(d_k)\n",
    "        self.k = layers.Dense(d_k)\n",
    "        self.v = layers.Dense(d_k)\n",
    "\n",
    "    def call(self, x):\n",
    "        Q = self.q(x); K = self.k(x); V = self.v(x)\n",
    "        score = tf.matmul(Q, K, transpose_b=True) / tf.math.sqrt(tf.cast(self.d_k, tf.float32))\n",
    "        attn = tf.nn.softmax(score, axis=-1)\n",
    "        return tf.matmul(attn, V)\n",
    "\n",
    "def split_inputs(X99_scaled):\n",
    "    z = X99_scaled[:, :96].astype(np.float32)[..., None]   # (n,96,1)\n",
    "    stats = X99_scaled[:, 96:].astype(np.float32)          # (n,3)\n",
    "    return z, stats\n",
    "\n",
    "z_train, s_train = split_inputs(X_train_s)\n",
    "z_test,  s_test  = split_inputs(X_test_s)\n",
    "print(\"z_train:\", z_train.shape, \"| s_train:\", s_train.shape)\n",
    "\n",
    "def build_z_catnet(num_classes=33):\n",
    "    inp_z = layers.Input(shape=(96,1), name=\"z_input\")\n",
    "    x = layers.Conv1D(32, 5, padding=\"same\", activation=\"relu\")(inp_z)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv1D(64, 5, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "    x = SelfAttention(d_k=64)(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "    inp_s = layers.Input(shape=(3,), name=\"stats_input\")\n",
    "    s = layers.Dense(16, activation=\"relu\")(inp_s)\n",
    "    s = layers.BatchNormalization()(s)\n",
    "    s = layers.Dense(8, activation=\"relu\")(s)\n",
    "\n",
    "    h = layers.Concatenate()([x, s])\n",
    "    h = layers.Dense(128, activation=\"relu\")(h)\n",
    "    h = layers.BatchNormalization()(h)\n",
    "    h = layers.Dropout(0.4)(h)\n",
    "    h = layers.Dense(64, activation=\"relu\")(h)\n",
    "    h = layers.Dropout(0.3)(h)\n",
    "\n",
    "    out = layers.Dense(num_classes, activation=\"sigmoid\")(h)\n",
    "\n",
    "    model = keras.Model(inputs=[inp_z, inp_s], outputs=out, name=\"Z_CATNet\")\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss=focal_loss(gamma=2.0, alpha=0.25),\n",
    "                  metrics=[keras.metrics.BinaryAccuracy(name=\"bin_acc\")])\n",
    "    return model\n",
    "\n",
    "z_catnet = build_z_catnet()\n",
    "hist_cat = z_catnet.fit({\"z_input\":z_train,\"stats_input\":s_train},\n",
    "                        y_train,\n",
    "                        validation_split=0.2, epochs=50, batch_size=64,\n",
    "                        callbacks=callbacks, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1054bbf9",
   "metadata": {},
   "source": [
    "## 10) Evaluation (micro precision + per-class Precision/FPR/FNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd30ea7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def per_class_metrics(y_true, y_hat):\n",
    "    rows = []\n",
    "    for j in range(y_true.shape[1]):\n",
    "        yt, yp = y_true[:, j], y_hat[:, j]\n",
    "        TP = np.sum((yt==1) & (yp==1))\n",
    "        FP = np.sum((yt==0) & (yp==1))\n",
    "        FN = np.sum((yt==1) & (yp==0))\n",
    "        TN = np.sum((yt==0) & (yp==0))\n",
    "        precision = TP / (TP + FP + 1e-9)\n",
    "        fpr = FP / (FP + TN + 1e-9)\n",
    "        fnr = FN / (FN + TP + 1e-9)\n",
    "        acc = (TP + TN) / (TP + TN + FP + FN + 1e-9)\n",
    "        rows.append([j+1, acc, precision, fpr, fnr, int(yt.sum())])\n",
    "    return pd.DataFrame(rows, columns=[\"class\",\"accuracy\",\"precision\",\"FPR\",\"FNR\",\"support\"])\n",
    "\n",
    "prob_er = er_ann.predict(X_test_s, verbose=0)\n",
    "pred_er = (prob_er >= 0.5).astype(int)\n",
    "\n",
    "prob_cat = z_catnet.predict({\"z_input\":z_test,\"stats_input\":s_test}, verbose=0)\n",
    "pred_cat = (prob_cat >= 0.5).astype(int)\n",
    "\n",
    "micro_er = precision_score(y_test.reshape(-1), pred_er.reshape(-1), zero_division=0)\n",
    "micro_cat = precision_score(y_test.reshape(-1), pred_cat.reshape(-1), zero_division=0)\n",
    "\n",
    "print(\"Micro Precision ER-ANN  :\", round(float(micro_er), 4))\n",
    "print(\"Micro Precision Z-CATNet:\", round(float(micro_cat), 4))\n",
    "\n",
    "m_er = per_class_metrics(y_test, pred_er).sort_values(\"support\", ascending=False)\n",
    "m_cat = per_class_metrics(y_test, pred_cat).sort_values(\"support\", ascending=False)\n",
    "\n",
    "display(m_er.head(12))\n",
    "display(m_cat.head(12))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f65628",
   "metadata": {},
   "source": [
    "## 11) Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29578da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(hist_er.history[\"bin_acc\"], label=\"ER train bin_acc\")\n",
    "plt.plot(hist_er.history[\"val_bin_acc\"], label=\"ER val bin_acc\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"bin_acc\"); plt.legend(); plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(hist_cat.history[\"bin_acc\"], label=\"Z-CATNet train bin_acc\")\n",
    "plt.plot(hist_cat.history[\"val_bin_acc\"], label=\"Z-CATNet val bin_acc\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"bin_acc\"); plt.legend(); plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f87612",
   "metadata": {},
   "source": [
    "## 12) Export CSV (đưa vào paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4504f9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame({\n",
    "    \"model\": [\"ER-ANN (paper)\", \"Z-CATNet (proposed)\"],\n",
    "    \"micro_precision\": [micro_er, micro_cat],\n",
    "})\n",
    "display(summary)\n",
    "\n",
    "m_er.to_csv(\"metrics_er_ann.csv\", index=False)\n",
    "m_cat.to_csv(\"metrics_z_catnet.csv\", index=False)\n",
    "summary.to_csv(\"summary_metrics.csv\", index=False)\n",
    "\n",
    "print(\"Saved: metrics_er_ann.csv, metrics_z_catnet.csv, summary_metrics.csv\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
